
# LARGE SCALE IDEAL POINT ESTIMATION

## 0. Directions for Replication
To replicate this project and run on yourown there are a few steps you should follow. 
### 1. Download the Data:
  Download the 1m data from https://grouplens.org/datasets/movielens/1m/ into the MovieLens-1m folder. 
  I did not share the data to respect IP rights of MovieLens. 

### 2. Run the pre-process.ipynb

  This creates the files in the cleaned version, as well as a train/test split.

### 3. Run the Estimation Code
  There are two different estimation methods used: SoftImpute and emIRT. The code for these is in R. 

### 4. Result Exploration

  This is the main analysis file. Optionally, if you want to compare with Perry's methodology there is a section in the result exploration folder. However, there are additional features for this comparison. Those additional features can be generated by running the "make-feature.ipynb" notebook.

Below is the report I wrote for this project. 
  
## 1. INTRODUCTION
    
### 1.1 Ideal Points

Ideal point estimation models are widely used in political science and economics to quantify spatial terms like “left” and “right”. With the enhancement of ideal point estimation models and the increasing availability of data, the ideal point estimation methodology has been applied to various settings. For example, Bafumi and Herron estimated the ideal points of Congress and the voters to examine the representation of the public (Bafumi and Herron, 2010).

Moreover, data with different structures and sizes started to be used for ideal point estimation. For instance, Barbera utilized unstructured text data from Twitter (now known as X) to estimate the ideological positions of more than 40 million users. (Barbera, 2015) Bond and Messing performed similar research to predict the ideal points of 6.2 million Facebook users. (Bond and Messing, 2015).

Most initial work on ideal point estimation is mainly inspired by item response theory. Item response theory is a model for analyzing tests and questionnaires. The mathematical models developed for IRT assume the following: The performance of an individual in a test item depends on the individual's overall performance and its relationship with the specific test item. For example, consider the test score of a student in a mathematics exam. Firstly, this score would depend on the overall ability of the student and the general difficulty of the test. Secondly, the score would depend on the relationship between the student and the test item. For instance, the student may be inclined to perform well in mathematics but not in qualitative subjects. So, the relationship between the student and the test would determine a part of the final mark that is not explained by the overall performance of the student or the difficulty of the test. In this example, the relationship fit represents the position of the student in the quantitative/qualitative spectrum, communicating his/her tendencies.

In ideal point estimation methods, a similar framework is employed. For example, what policies legislators vote for depicts their political positions. In this case, instead of test scores, the "yes" or "no" votes would be used as performance metrics. If the relationship between voting "yes" to conservative policies and an individual is highly positive, his/her tendencies would signal a right political standing.

### 1.2 Recommendation Systems

Recommendation systems gained importance as e-commerce emerged. Due to an overwhelming selection of products, consumers started to rely on recommendations that are tailored to their preferences to make the buying decision. Recommendation systems are a class of machine learning algorithms to predict which product or service a user is likely to purchase/select. These algorithms are utilized by the major players in the tech industry such as Amazon, Google, and Netflix.

The recommendations mainly depend on two types of filtering or a mix of those. The first type is collaborative filtering. The key idea behind this is that if different users enjoy the same product, they are likely to enjoy the other products that their counterparts purchased before. So, these algorithms use the information on the similarity of the preferences. The second type is content filtering. These algorithms aim to find the underlying patterns in products and make recommendations with that information. For example, movie recommendations based on genre or cast information fall under this filtering category. 

Overall, recommendation systems increase the profitability of businesses. Indeed, McKinsey consultants report that 35% of Amazon’s revenue and 75% of Netflix’s streams are generated by their recommendation systems. In alignment with this success, Netflix created an open competition for the best collaborative filtering, also known as the Netflix prize. This competition boosted the recommendation algorithms research.

### 1.3 The Purpose

In this paper, two different methods are used to generate movie recommendations. The first approach uses ideal point estimation to assign scores to users and movies. The movie effect fit and high compatibility estimates between the ideal point estimates for the user and movie characteristics generate a recommendation. This method provides an innovative and hybrid recommender system taking into account both collaborative and content filtering. The second approach is the application of a fast matrix completion algorithm. This is more closely related to collaborative filtering but generates similarly successful recommendations.

## 2. DATA
    

### 2.1 Description

In this paper, MovieLens 1 million data is used. (Harper and Konstan, 2015). Unlike other versions of the MovieLens data, the 1 million version includes not only movie ratings but also some user demographics. In this dataset, there are three files: ratings, users, and movies. In the ratings file, there are 1,000,209 anonymous ratings of 3,706 movies made by 6,040 users. For each rating, user ID, movie ID, timestamp, and rating score are provided. Ratings are on a scale from 1 to 5 with 1-point increments. The histogram of the ratings is provided below.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfMKgF7yigymq7j0UahHMqLJPJjq4fymeH8jSnNAxMaQWva8idEDqZXxzQdccLDNxtTIfZX1ZsgbyDzNaOpf0MD2llh6VCbT5JwHIyHwbCmpVvoNXDxvuPuunP11L9zphHnCzE0FzlmmFcSEorG2oWCfsT9?key=HJWLvVuM2SkyCk2nopk7bA"  alt="The histogram of normalized ratings."  width="400"/>

In the movie file, there are records of 3883 unique movies. Some of those movies are not included in the ratings file because they received less than 20 reviews. For each movie, the movie ID, title, and a list of genre types are provided. There are 17 genre types which are Action, Adventure, Animation, Children’s, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, and Western. Note that a movie can have multiple genres. For example, Toy Story’s genres are reported as Animation, Children’s and Comedy. The most common genre is Drama with 1603 movies, and Comedy follows it with 1200 movies. The least common genre type is Film-Noir with only 44 movies.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXelP_cJzT1prERvroU_yTrn65_wcZpNbftgzg55oMO6EsZWE5Enmx-hqanJjItNTFxkx2nKQcGS2bPwHbvbhxxFcSx8l095c5De97PIqQd7K2mw9naw4aP445jPd14GHF0mbGPZYx2PkWujybphUrET_G2n?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

Lastly in the users file there are 6040 unique users. For each user, user ID, gender, occupation (categorical), age (categorical), and zipcode are provided. The age categories are (1-17), (18-24), (25-34), (35-44), (45-49), (50-55), and (56+). Below is the histogram of the user’s ages. The most common age group is (25-34) with 2096 users in this category, the least common age group is (1-18) with only 222 users. Most of the zipcodes provided are valid with around 300 invalid ones. All of the users are located in the United States. There are 21 occupation categories: (0: other),  (1: academic/educator), (2: artist), (3: clerical/admin), (4: college/grad student), (5: customer service), (6: doctor/health care), (7: executive/managerial), (8: farmer), (9: homemaker), (10: K-12 student), (11: lawyer), (12: programmer), (13: retired), (14: sales/marketing), (15: scientist), (16: self-employed), (17: technician/engineer), (18: tradesman/craftsman), (19: unemployed), and (20: writer). The most common occupations are college/grad student with 759 observations, other with 711 observations, and executive/managerial with 679 observations. MovieLens explicitly states that this data is reported by users themselves and may be subject to inaccuracies or false reports.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXc9xLjT5EvAM-qPuCpT7rO2Yj6ud9boshY2rH7wKhINHZ0iu-zCZBNoJICwBMXcWJRFm77K0YpWH9X2F6kFVIplou1Sn_rZmEw6a1RWxLj-F8zLKLCt2ooh0v8RTVtuDB4JUqhzpPSqcU4fStclqUoB3jh_?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>
  
### 2.2 Pre-Processing

To be able to generate recommendations, a sufficient amount of data for each user and movie is needed. Therefore, users and movies with less than 50 reviews are filtered out. This leaves 4247 users, 2499 movies, and 918946 ratings. The histogram of the filtered ratings is given below.

 <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdMUiWDl4qA1Nt0sOT5j_-tauSq990mI0zlHDCCm7PfFIamegOD2TxGlRL520Pt8fT7vM4231UXpCRo12Fis1mbUezkThaZk1aqU9-aWORrTEZ62_KaFk-MR6xT_WaNts6qf14UqkHjWvmwKP9ACXkmuqSp?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>
  

The original format of the rating data is long. This means that each rating entry is represented by a row with columns as movie ID, user ID, and the rating score. However, both of the software that will be used in generating recommendations require a wide format. In the wide format, user IDs are row indices and movie IDs are column indices. The rating score is the value in the matrix with the ratings’ user and movie IDs as indices. If there is no rating for a movie by a given user, the corresponding matrix cell is left empty. In this format, 91% of the filtered data is missing.

 
Furthermore, in the ideal point estimation model, the y variable (rating) must be binary. Originally, ratings are recorded from 1 to 5. An initial idea is to set a threshold to binarize at 4 as Perry did in his paper. However, “liking a movie” is very subjective. Some people tend to give very high scores overall whereas some others are more conservative in assigning high scores. Therefore, instead of setting a generic threshold, user-based benchmarking is more feasible. One such way is to normalize ratings by subtracting the mean rating of each user from all of their ratings.

Below is the histogram of normalized ratings using that normalization approach.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdANMBYvQHG1eCZ9UPGc0seartFji60iEzooI2SY1R5fCUaJca6ZYM1c6VWfvOVR_3gQHtPIubIPQB-WXKqVXNZ4vFwQLO0dShngCRiwShPpkFiHaaEoZf-lA7p7Jt01swtI3Gh1PED9FJ34jJi_q-qsPg?key=HJWLvVuM2SkyCk2nopk7bA"  alt="The histogram of normalized ratings. (Original score - the mean score the user writing the review assigns)"  width="400"/>

After the normalization, deciding on a threshold is still an important step. Two alternative thresholds are examined. In the first one, a rating was deemed positive if it was at least 1 point higher than the user’s mean reviews. However, this model was highly conservative, assigning a significant amount of ratings as bad reviews. Indeed, with this method, 20% of the users did not give any positive ratings. In the second threshold alternative, a rating is considered positive if it is strictly greater than the user’s mean rating. This alternative is chosen because it conveys the information of what each user liked without being extremely conservative. The formulation of normalization is given below where $y_{i,j}$ is the rating given by user $i$ to movie $j$ and $\mu_i$ is the mean rating given by user $i$.

 ```math
 y^*_{i,j} =  y_{i,j}  -\mu_i
```
  

### 2.3 Train Test Split

To accurately assess the performance of recommendation systems, a test data set is needed. However, subsampling by users or movies is not an option here. Data regarding each user and movie is necessary to be able to generate recommendations for the movie and the user. Therefore, we need to take a random portion of the ratings and assign them as a test. In this way, we would keep some data about each user and each movie, allowing us to make recommendations for those. Applying this logic, 10% of non-missing ratings are randomly chosen as test data.

## 3. Mixed Models and Algorithms for Recommendations

### 3.1 Mixed Models

Linear mixed models extend the linear model $y = Xβ + ε, \quad ε ∼ N(0, Iσ^2)$ to $y=Xβ+Zb+ε, \quad b∼N(0,ψ),  ε∼N(0, Λσ^2)$ where random vector, $b$, contains random effects, with zero expected value and covariance matrix $ψ$, and $Z$ is a model matrix for the random effects. (Wood, 2006) 

So, a mixed effects model combines both fixed effects and random effects. The fixed effect part captures the features that are consistent throughout the population. On the other hand, in linear mixed effects models, the random effects part captures the variability at different levels. 

For fitting mixed effects models, various methods and algorithms have been developed including expectation maximization, variational approximations, Markov Chain Monte Carlo estimations, and likelihood maximization. 

### 3.2 emIRT Binary Model and Algorithm

The expectation-maximization algorithm developed by Imai requires a wide format of data. Each user is represented by a row index whereas each item is represented by a column index. In the binary model, the output variable $y_{i,j}$ represents the  propensity of user $i$  to cast a positive vote ($y^* >0$) to item $j$. Missing data is assumed to be random and ignorable. (Imai, 2016)

The standard K-dimensional model is given as, $y_{i,j} = α_j +x^⊤_i β_j +ε_{i,j}$ 

where $β_j$ is the K-dimensional column vector of item discrimination parameters and $α_j$  is the scalar item difficulty parameter. Finally,  $ε_{i,j}$ is an independently, identically distributed random error and is assumed to follow the standard normal distribution. Note that in this model, there is no vector for user fixed effects. 

The model is fitted by placing independent and conjugate prior distributions on $x^*_i = [1, x_i^{\tau}]$ and $\beta^*_j = [α_j , β^{\tau}_j]$. Given the prior means and covariance matrices for these vectors, the joint posterior distribution is maximized using the proposed expectation maximization algorithm. 

The algorithm works iteratively. At step t, it takes  $[x_i^{(t−1)}]^N_{i=1}$ and the next iteration is given by the "Q-function" which represents the expectation of the logarithm of the joint posterior distribution. The formula for the Q-function in this setting is given below.

```math
Q([x_i]^N_{i=1} , [β^*_j]^J_{j=1}) = \mathbb{E}[\log p(Y^*,[x_i]^N_{i=1} , [β^*_j]^J_{j=1}|Y) |Y, [x_i^{(t-1)}]^N_{i=1} , [β^{*(t-1)}_j]^J_{j=1}])
```

This maximization has a closed-form solution. The resulting values for the ideal point is given as
```math
x_i^{(t)}= (\Sigma_x^{-1} + \sum_{j=1}^Jβ_j^{(t-1)}β_j^{(t-1)⊤})^{-1} \times  \Sigma_x^{-1} \mu_x + \sum_{j=1}^Jβ_j^{(t-1)}(y_{i,j}^{*(t)}-\alpha_j^{(t-1)})
```
Similarly, for item discrimination and difficulty is given as:
```math
β_j^{*(t)} = (\Sigma_{β^*}^{-1} + \sum_{i=1}^N x_i^{*(t)}x_i^{*(t)⊤})^{-1} \times  (\Sigma_{β^*}^{-1} \mu_{β^*} + \sum_{i=1}^N x_i^{*(t)} y_{i,j}^{*(t)})
```
Even though this algorithm is designed for estimating K-dimensional item discrimination and ideal point models, in practice the software in the public R package emIRT() can only fit 1-dimensional models. Also, in the software observed $y_{i,j}$ values are inputted as 1 if positive, -1 if negative, and 0 if missing. 

### 3.3 SoftImpute Model and Algorithm

The SoftImpute algorithm, just like the emIRT, requires input data to be in wide format. Moreover, it allows numerical values of y. SoftImpute is mainly a matrix completion algorithm that fills the missing entries while minimizing the rank of the resulting matrix. By doing so, the algorithm tries to create dependent predictions that mimic the other users with similar preferences. The minimization problem behind the algorithm can be written as 

```math
\min ∥Z∥_*, st.
\sum_{(i,j) \in Ω} (X_{i,j}−Z_{i,j})^2≤δ
```
 This minimization problem can also rewritten as
```math
\frac{1}{2} \sum_{(i,j) \in Ω}  (X_{i,j}−Z_{i,j})^2 + \lambda ∥Z∥_*
```
Here, $Z$ is the resulting, complete matrix. $Ω$ is the set of indices of the observed $y$ values, and  $X$ is the initial incomplete matrix. $∥Z∥_*$, also known as the nuclear norm, is used as a regularizer. $\lambda$  is the parameter used for shrinkage of the nuclear norm.  (Hastie, 2010)

In the first formulation when $\delta$ is set to 0, the minimization problem requires 0 training error, possibly resulting in over-fitted solutions.  In the second form, a minimizer matrix $Z$ is available on the closed form and is given by $Z^* = S_λ(W)$ where 
```math
S_λ(W) =  UD_{\lambda}V^⊤ 
```
Where  $D_{\lambda} =\) diag \([(d_1 - \lambda), ..., (d_r - \lambda)]$
 In other words, $S_{\lambda}(W)$ is the singular value decomposition of $W$.

The SoftImpute algorithm solves the minimization problem in the second form using the result provided above. One advantage of this form is it relaxes the rank constraint. So, instead of calculating both SVD and optimal rank for minimization, only the SVD iterations are calculated and rank reduction occurs at the same time as shrinkage. At each step, the SoftImpute algorithm iterates between filling the matrix with the current SVD and then updating the SVD using this new complete matrix. 

The first iteration starts with filling the missing entries by 0. Thus,
```math
P_Ω(Y)_{i,j} =
   \left\{\begin{array}{lr}
       Y_{i,j}, & (i,j) \in Ω \\
       0, & (i,j) \not \in  Ω 
    \end{array}\right\
```

Then, the new matrix is calculated as 
```math
Z^{new} = S_{\lambda}(P_Ω(X) + P^⊥_Ω(Z^{old}))
```
If $Z$ converges the algorithm is exited. If not, $Z^{old}  ← Z^{new}$ and the loop continues until convergence occurs or the maximum number of iterations is reached. 

### 3.4 The Link Between emIRT and SoftImpute

Even though, SoftImpute and emIRT algorithms look greatly different there are certain similarities. Hastie et. al. establish that SoftImpute and Maximum-Margin Matrix Factorization models are closely related. MMMF solves the minimization problem 

$$\min_{U, V} \frac{1}{2} || P_Ω(X - UV) ||^2 +  \frac{\lambda}{2}(||U||^2 + ||V||^2)$$ where $U$ is an $m$ by $r$ and $V$ is an $n$ by $r$  non-orthogonal arbitrary matrix. Hastie proves that under some conditions the solution space of SoftImpute is contained in the solution space of MMMF. These conditions are $r = \min (m, n)$, and  $Z^*$  is solved under $\lambda > 0$  with rank $r$. In other words, under these assumptions, a solution to the SoftImpute minimization problem is also a solution to the MMMF minimization problem. 

In addition to these, note that the solution to MMFF is equivalent to the solution of the random effects model where $Y_{i,j}$ is Gaussian with mean $U_i^⊤V_j$ and variance 1. In the emIRT model, there are also fixed effects for items but the random effects part is identical to the MMMF model. So, SoftImpute and emIRT minimize very similar models, the first one only captures the random effects and the latter one captures both random effects and fixed effects for items. 


## 4. emIRT-BINARY IMPLEMENTATION
    

### 4.1 Priors

In this model, the hyperparameters are fixed by priors. Therefore, a mean and a variance must be determined for user ideal points, movie discrimination, and movie effect (difficulty). The mean for all these variables is set to 0. By default, the variance for difficulty and discrimination is 25, whereas it is 1 for user ideal points.

We change the variance for discrimination to 1 because it interacts with the ideal point estimations via multiplication and a similar scale for comparisons is desired. The variance for movie difficulty is left unchanged.

### 4.2 Model Fits

After fitting the model three vectors are returned. User ideal points refer to the random effects estimates for the multiplicative component of the users. Originally, the intercepts are called difficulty by Imai. However, in the context of movies, the difficulty of a movie does not make much sense. Therefore, we will call this component the movie effect. Finally, the last vector, movie discrimination, refers to the random effects estimates for the multiplicative component of the movies. When multiplied by the user ideal point estimates, this number depicts the fit between the user and the movie.

 <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXeWfQg3hfm9sZb1NyPDPBpwZMctGzOT8BIKbutL8zhFIytwsTwPNlTocbbzzP95n5k0hXbFepiokXQJ73V6N9E4gcym59vGw1UFUG1gAWa4z8eRPGWw0r5yEC-qtsoR-vaAQDAOhE75SNFH2dFE9laaVeM?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>
  
In correspondence with the fixed hyperparameters, the mean of the ideal point estimates is 0 and the standard deviation is 0.434259. The minimum ideal point assigned to a user is -1.68 whereas the maximum is 1.97. The histogram of the user's ideal points can be found above. Note that these estimates are generated only using the train data set.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfFkX6g_KWWp6xaFYWRWXkqWoU-L4p8IrqdPZcFuMidCayhhk08N87mawvrMkhrGp9l9M9Wu6JV3p16w5bMrZt7NW3-UTih_366-SF2tjeIF_h60LCFivjX7CmzpWnyFXXjGdnrsv819erGV2lLbXC_0rT6?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>
  
The mean of the movie discrimination is 0.99 and the standard deviation is 0.46. The minimum discrimination score assigned to a movie is -1.23 meanwhile the maximum is 2.59. Since the algorithm does not allow for user fixed effects, it fails to satisfy the zero-mean condition for movie discrimination. However, addressing this issue is beyond the scope of this paper.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfJ9WJSH4Swgywp01O8feiE1jR5dRePwy-NMvALM1Xi9DbhkIG11lD_BJrCCTV3PuInWsVnUlibBlQwUe-2mdrTr7JS2LG7JX6t4Et_ipiHDkHDB_qOhYa0A2DRYI1RQtvMCQ0B87e_ilzET2NIEW4mfTg?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

The mean of the movie effect is -0.18 and the standard deviation is 0.67. The minimum difficulty score assigned to a movie is -2.09 meanwhile the maximum is 1.57.

### 4.3 Model Fit Analysis

Since the emIRT software allows for one-dimensional interactions, it may capture unexpected properties in the data. The scatter plot below demonstrates the number of reviews a user has written on the x-axis and their ideal point estimate on the y-axis. There is no clear strong relation between these variables. However, when the x-axis is set as the ratio of positive ratings given by the user, a significant correlation is displayed.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcLXdrg2HA01Qf0rnkyVQksrd8N0IQDcLrCVl6b0iVIe5iXJTLyueDqI_d4OKjEIz4hRG7A6Aqh8FD9a9oEwpR6UQyPHEp_vWUU34ibwutBXQ72YuYrIBjRRzWgVFEFkHOOMiNq5DN2aRhV3ZOSlIboOtg?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfnnHICHHuG2V6upc0Q7F3t9NDHkZmZ0GXgNQqf80BuHP-SjbL0ZLH2jipnTcM1v52o-RgC30DerGOOkTT-UFYumHK_0s4H_JgSIeg5ikA1Atg6B-EHgghfDGKHUclDIbtXtNwn-xCw7ChwJj4t5ktP-7ix?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

Recall that a positive rating indicates a rating that is strictly larger than the mean rating of that user. For example, if a user rated (4, 4, 4) three movies, her positive rating ratio would be 0. On the other hand, if a user rated (1, 5, 4) his positive rating ratio would be 0.66. Considering this strong correlation between the positive rating ratio and the ideal point estimates, we can guess that the first dimension of the user’s multiplicative component corresponds to how positive a user is on average.  

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcupRn3qSoMbyyuQT4LSycB0goRVpRbeJj3VKUTa9fsvATLQE1AXa0p7_FyQsr--arDq08TotDhm1c5C26IdGIhYnf4Sq5r_2jgLDCNyzUzlQmuK1MNOoTwu-ottoDcmbVBXsvpSWrq053Ctd7QYSqUB5s?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

As can be seen above, there is no strong correlation between the movie's difficulty and the movie's discrimination. This shows that movie effect and movie discrimination capture different aspects of the data which increases the performance of the model. 

With the insight we gained from the relationship between the ideal points and the number of positive reviews, we first examine the number of reviews a movie received and the estimates.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXc9uQQfzfGcOACBUjvfqq8FszsirkdmAoG0RLHgKOjnCJMTfXcgARPtYxleGbkwlVg0l67nuuIIGcDRS0R576UQmB-34_y0N-A_eBIjkh8SrKGqAkSjVW8njUUfH_dvVHLX_u6YawhBd4o61NafG4pZKec?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>


<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcW5VbBvNGMJI5ycOIsowNmbaxFJg5qIxnHhtRIG49UaWftP7LdKshtgMjQgWPHMKnR2-EwP_46VtZdOGMyFB2MB0EUyW4NfroLAT09zOhhUWmJFhcfXfSvzZiGk1PRPIVhVZHCzmXgcEykZDJJ-AcClsh8?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

From these plots, a strong positive correlation between the number of reviews and  these estimates is apparent. So, the model may be learning the popularity of a movie as a recommendation metric. To examine this further, we look at the positive rating ratio of movies.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXeF-x6hORJw3JW8OGZVY2yk2ltjQH7ZDlVdMLN-FW3QeZoIMqabrmJ75hOqCP33g764y6LUcucFDU3daNPP2unuks93loqKkNLo-A8evu0tZbqD_XcnF5ezidjU_QJZ2e6xhlvwrCvMHZe6JBPV-DeVReSv?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

  
  <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXe6wEkmFHy9yxNvAMx451gD5FsgTYPr6ydtRm58YwzQuwFX0gYGbYZxymBkWG5Gb_FHJHoj3TxbBOftklizA8VVcdTWd_0L0QtKvGxmqKW9J09k0QreQSUSUB2sas8ZVz70VXvXVNecrw_SmhY3wTc7z_a4?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

Indeed, the correlation between the movie difficulty estimates and the positive rating ratio of movies is 0.987. So, we can confidently say that as expected the fixed effects estimator picks up the average liking ratio or quality of a movie.

Perry proposes a logit popularity indicator to be used in recommendations as a fixed effect. (Perry, 2017) We expect the movie effect estimator to be correlated with Perry’s logit popularity metric. However, Perry binarizes ratings around 4. To maintain consistency, we will keep our binarization method and calculate his index based on that. Furthermore, Perry's logit movie popularity metric depends on the timestamp and gets updated with each new rating. However, movie effect estimates are calculated with all the available data regardless of the timestamp. To match the frequency of these statistics, we will use the mean logit popularity for each movie.
  
 <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdlsGM0hIsvI-sbFUsTDTIDgkIoEnQtUiye9k41B0Kl1wCrwUTxZdY3jtTn2_-Fn5Z9FsNHAR_nXBpstrygtlib1uS41W8lOr-o0lksA5XjoPKPbY_g-jHr4KFmBdz9c-nPoQ-_5ExCPsm3IbOOCEYDwyZm?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

In alignment with our expectations, the correlation between movie effect estimates and mean logit popularity is 0.96.
### 4.4 Model Performance

The rating predictions for the test set are calculated. The estimates for whether the user would like the movie (y = 1), or would not like the movie (y= -1) are spread out with a mean of 0.12 and a standard deviation of 0.71. The highest estimate is 3.3 and the lowest is -4.2. The histogram of these estimates is given below.

 <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfpMVA_GVY7ekfXEZT6vfc7hY5K2ojs1y7rlnZ7hqBS-Z_Z4GpidcbqBmHva2sY3JvNCMO1RO6FG1ds6GwzI5A0oReaSR12piQzGqu2Bk-XxXQahmVczOEnun9ejsXBWre54S91nc_DyOx-dHAZ4vIhAv4?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

A binarization is necessary to convert these estimates into recommendations. Setting the recommendation threshold to 0, the model estimates that user $i$ will like the movie $j$ if the rating estimate, $y^*_{i,j}$ is more than 0. Comparing those binary estimates to true binary ratings, the accuracy of the model is 0.7. The confusion matrix is given below.
  
   <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdZNkfs8PMgZ1gI_FaJqFEc3x-FDuwqH_iXm4TnRFdSlk1G64dwzZY05ho4WY-4X-JLV7uGyiBGJUMPGWGTyrUFPyk1VISU8bEdxoSdTiNVLnFYUa_oeJ8ACXMevs7_HQnJaiq0nnu1pO6uEDlkY6gdH_qX?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

However, it is important to note that this binarization is very naive. Simply, we recommend a movie if the probability of it being liked by the user is predicted as more than 0.5. An alternative way to assess the model's performance is to evaluate its ROC curve. Since the model estimates the propensity scores and the errors are standard Gaussian, we can calculate the cdf of these propensities with respect to standard Gaussian distribution. Thus, the resulting ROC is given as below.

   <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdxnEE-ftgAlbo6Y_f1fu1E2cCUVKJXWVBv0cV1KzZPlykQqTNHrrzXaioL5J8NS1Yea9hvdzkucEGfb-gYHd6JhHPNdGRIUeMZOK2zLRsKSMaMg-pMdrzEAj58ACiGHL7wx6S65P2W9C4Dl7GW7nx6vMFz?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

### 4.5 Content and Context-Based Comparisons

As discussed in the introduction, some recommendation systems aim to learn the content and context data to generate recommendations. The emIRT model predicts a movie effect, discrimination, and ideal point estimation. These estimates might be correlated with some demographics, providing innate content and context-based filtering. MovieLens provides some user demographic data such as zip code, occupation, and gender. For the content part, the genres of movies are also given. So, comparing the estimates with those might provide further insights.
   <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXc3u4BdhS97ApgQHzXR5ItcDw0tYeUehPQtbE106UBMBVuuQn8Xupo5_rRcL30OrV_gMJq0KCs1vE9vxL1_zefwW6jnt3znepOxaNTVz7rSg1PmMmPaC-hZuyfWMf_3mrB4i6ivdTc5hEujJ1EejiEuFroo?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

This distribution of users on the map is expected considering the population densities of the US states. The average ideal point in each region is close to the population mean.

 <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdH6nRzA53-vUhRAyifhFa0NFQEF8CoJliDJB-y4LTpcs9gzmSO7C_DlIxcubSQoRiXY-jPz-gDGMFe5nM1r2XlmCJHtiz2pUyAt91feDwn6Fmy9_iJLabp0tQLCqlKyT3ES15TWUwH0hty8Tdf3hDxdUc?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

There are more outliers in ideal point estimates of males than females but overall they follow a very similar distribution.

There is a negative correlation between the age of the users and the ideal point estimates. However, each category follows a similar distribution overall.
   <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXeQNw3N4F8auUFfdt3BMe72Dyoin1f4ExsXfizaJVOllKPMSntC-2Rleg97EWJVNAR3MczXQy27wOKdgq8aJfCvJwHMf0JmeDc95Y3TR4u50OIugQShID_mDHdC4q0dNfLpS1QxLxXaspfsvpupDQcu_OsD?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

There are many job categories, some represented by only a few observations in the data. Therefore, the five most common job categories will be discussed. Here category 4 refers to college/grad student, 0 other, 7 executive/managerial, 1 academic/educator, and 17 technician/engineer. The educators tend to receive a lower ideal point estimation and executives and engineers have more outliers on the negative side. Students and engineers have a higher average ideal point estimate.

   <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXekPdffuT2GQInbrQPo-VEY_BBknBrBG47igfkDYwXO64PF-1K4GLpT-WbN-8tXEfk-qltvT4JUrDtH3AXBS2SH8Vc1vbBeFnXjB8GRF847t6S_kyW9WFB2JPcA18lNueucWHYtndbw6VxUtmKwrv17-t96?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

For the movie discrimination, Action, Horror, Thriller, Children’s, and Comedy genres have many outliers on the negative side. Horror, Documentary, and Musical are the only genres with a median movie discrimination of less than 1.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXf_vrzoNwt1mJpxeW4tqt0KGwuAZamDzkYXmDnalfZveN1qTO7IEjcpesjrVtVIdW7zWBO5ZMlL6LZTpj5TfGY7fTeVA_BER1IdGAWrhJXasQIQ9ra1L4fLcBD9bhKzryrMGyyFJWZ9JKtj4GBOL0PNTeiv?key=HJWLvVuM2SkyCk2nopk7bA"  width="450"/>

For the movie effect (difficulty), Documentary, Drama, War, Western, and Film-Noir genres have the highest median scores. Considering that these genre types received a relatively lower movie discrimination estimate, we can conclude that even though these movies are liked overall, they require a certain type of audience.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcgvhmk1dr4-ltoL47Kkh3_X_DAN219zjOLBCfa2_P-aATMSlvrO_H6_9xs1vvPGPDzlMnEOSYQHiWqBNNyu1suLSlnZ-kksLUD87v_hyR5ljUjKIDgdEhENjxnSpzQ0xEaBi1Cw1QoZQySheERbxc9edE6?key=HJWLvVuM2SkyCk2nopk7bA"  width="450"/>


Finally, we would like to see if the model can capture any differentiation between high-ideal point users and low-ideal point users. We define a user as a high ideal point user if their ideal point estimate is more than 1 and as a low ideal point user if their ideal point estimate is less than -1. Then, we look at the mean rating of these extreme ideal point users for each genre. The barplot of these are available below.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfXa1GnqBy1wirikf8vo6bfdocvooyosgJLgONPm-R1ugxYTwwYFuZUv0_0ASXAEoiXHKZEp_yZkFZUiBmMJrsM383kkw5fKn1Ho7GIaILNBTDyYY7QDTtH_ZZr9oNsHck7JoHnSdawoqJwAbsgzdmrvgND?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcRkoD-VSViQfohmG3mCrWMJqApNpMnxy0dcHF5BBNyKf2Cl6zYOCfbpY-zRjWEjoyJZe78jPM0zXGhFiXrvRx6cXzNVtpYfBnkdM3qCEOocNkwVpnZZ5ov4QCsiC5enYh4PsLyUxDnIuSjM7lveCHmPHc4?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

There are some strong differences between high-ideal point users and low-ideal point users. Firstly, high ideal point users give overall very high ratings to documentaries and film-noir movies. We can conclude that the ideal point estimates strongly differentiate documentary, drama, and film-noir lovers from others. Also, high ideal point users give overall higher ratings to other genre types. 

## 5. SOFTIMPUTE IMPLEMENTATION
    

### 5.1 Input Structure and Parameters
Unlike the emIRT model, softImpute does not require binary output variables. Indeed, in the initial paper by Hastie et. al., it is used to complete the rating matrix that takes values from 1 to 5. Therefore, instead of using binary values normalized around the mean ratings, we will use the original data provided by MovieLens.

However, the SoftImpute algorithm requires specifying a nuclear norm and maximum rank for fitting the model. We will use rank 1 to draw a better comparison with the emIRT model. As the nuclear norm grows, it is guaranteed that train error will monotonically decrease. But obviously, the norm that minimizes the test error is unknown. Thus, we will use a cross-validation method to decide on an optimal value for the nuclear norm.

The software provides the minimum lambda value, called lambda0, for which the train error is 0. This is the upper limit in our lambda search. For efficiency purposes, a 5-fold cross-validation is used. The grid search for lambda starts from 0 and ends at lambda0. The test errors for all the lambda values tried are given below. 
  
  <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdOP6zUnxXx-K60DZwtHsR70HGcGqcQP0gjZyygWHkx0CfS6XAM2n3AcZ_yj1lb2PWWQ-WqdzTh4JhayyxcV8mx_RY2X2O0lYY4RtP66AHuK8tpcE8l07QaWlLdOxNI7Mj3O86nEedzyy1XOFFD_-WhRQV6?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>
  
The test error increases as lambda reaches lambda0 because the model fits values around 0 to all the missing entries. The minimum is reached when the lambda is 0. Thus, it is chosen as the parameter. This 0 lambda model, is equivalent to the HardImpute algorithm.

### 5.2 Model Fits

After fitting the model, we have a complete rating matrix. In this prediction, initially known ratings are not changed and only the unknown, previously missing cells are filled. The distribution of all the ratings in the train set is given below. Estimates have a mean of 3.57 and a standard deviation of 1.08.

  <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXc0YdWWyczaGl0aRPn4NEBd6xV7AShO1D7wpJr9dRb9ee-aiYmZNPbmpdyCFsXKOULfiEdPYVkgik6W_PD-URoHbBOqyT2LTOiptrGi5k1ae43kqj-ajzaZujOyS0_shzVRKtnYm8NxlE7H7ziHSjtxsyo?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

Applying the normalization by subtracting the mean user ratings, gives a more symmetrical distribution with mean around 0.

  <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXf31pNniqrM7BDlm6X2q6oB9QNyr1QEzFOs7Ury104Ok-sLtRbpAqzcmIFNu1_n0iPchvRTFpBsjSctaFYOaGvgajbi3FeDED6CYHWlTAXYP2Va1ishvE1sheHYUYcyz01SjmJMgaPtXrc67zVS_N8fCq0K?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>
  
Performing the same comparisons between the estimates and review counts, we see that the correlation is not as strong as in the emIRT model but is still positive.

 <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcaeTPnYyF6GAf2nrqYxIaHx5Y3QA-eBzAUAU_mfaWC11tzuQ2yeLN6PeQ76QIjs-zqeAVHZmzkyE5AFHAp_ksVg1oyB_WLfuPr5H6YEdTd3Mxzr3rbUTycoC9gpUSdED-LJ7V7xmmhyRnY6FO-r4vz_mTw?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

As expected, there is a strong correlation between rating estimates and the positive ratio of ratings that a movie receives.

 <img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdJhh7m9_igd2f_j9p7wQ5jBJaukGbgF0ii7s32d4BDEbo9dkwPsAkhznWmq6vS9RfUXJq5TCsdktoSXMXKR4KW0G2vUvNnCzA-bz8biD25vJRk21VejsOQyjlgkKytMEtzPDJH_RUUr7o5X13LfULTg_ii?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>


Unlike in the ideal point estimates, there is no strong relation between the positive ratio of user comments and the mean SoftImpute rating estimates done for the user. 

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdXF8G19UzGzvC5PWgBqfY5GzyhiL096OYZrfAtSP03DcGXC_BJh2UjlBbecsBEKiKmepV7GHwTEHutYOa-UCgIPsbgLlEBw6RYg9OxwoeHSgGMlrjCy4N-s5EbJZZ0HJFARuhlzX_wfq7VFFS0yfbgG5mB?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>


### 5.3 Performance

SoftImpute’s estimates of the test data are spread out with a mean of 3.53 and a standard deviation of 0.7. The highest estimate is 6.7 and the lowest is 0.6. The histogram of estimates is given below.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdIEefSd7LEg102DSGWm6hPjW6Og1LOoXyHQO5_OoqgIx78fa-ifYZTYFsvj83HRbYn4VJ9Ox7fgQWhqCQzIAIHVVO7FhVmnVPntUI0me9WO0Hm1kLUX7V3CaoUKOxL27qMYBY5RlLTCcTgguze98ZNC4qf?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

Since we scaled the ratings with user means in emIRT, applying the same scaling to SoftImpute predictions results in the histogram below. The mean of this new variable is -0.05 with a standard deviation of 0.58.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXfIomQQgC2IBlyHvaMFfjJTAu1oHD4JXYJ2eXwf3_z9c3f5sYbbqL9zozekj5mI9xwj6CRnXI1I51MmF9fGMkJ43mgG1cUSi2WK33-qerd1xvhhT-_YaJcXeLI_rhlqQ_dsrxSfgosVIBjWzHH4WGYt6o9g?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

To be able to compare the performance of SoftImpute with emIRT, the numerical predictions of the SoftImpute are binarized. If the rating estimate of the SoftImpute is more than the mean rating of the user, that prediction is categorized as 1 and 0 otherwise. The accuracy score of this classification is 0.65 with the corresponding confusion matrix below.

<img  src="https://lh7-us.googleusercontent.com/docsz/AD_4nXdyTI1UIN4tA0gWcy4lnDf1nU5h8bqHFniMMg2jkWqLj4Aqm2cW106kvfS0qtUJ8Dah7PX5Lc886dOAr598IO_w1KTBvL00PjJ7cb8d3XFdw6IWxaILWFjB25GgEFyst8xa0wmFmP-VNyqPJ05Z-zK5BRdR?key=HJWLvVuM2SkyCk2nopk7bA"  width="400"/>

However, we are not limited to accuracy scores since we have numerical data. The mean square error of SoftImpute estimates is 0.85.

## 6. Conclusions

This study compared two distinct methods for generating movie recommendations: ideal point estimation based on expectation maximization and matrix completion via SoftImpute. Through a comprehensive analysis, several key insights emerged.

Firstly, ideal point estimation offers a nuanced approach by incorporating both user preferences and movie characteristics. The fixed estimates for movie difficulty (effect) fit the overall quality of the movie while the random effects components address the variational differences in users and movies, revealing some user preferences and movie features. This hybrid method, which intrinsically blends collaborative and content filtering, demonstrated its potential to accurately match user preferences with suitable movie recommendations. The application of this model to the MovieLens 1 million dataset highlighted its robustness in handling large-scale data while maintaining the integrity of recommendations.

On the other hand, SoftImpute provided a streamlined and efficient alternative to the norm of generating recommendations via matrix completion. This method primarily leverages collaborative filtering principles, predicting user preferences based on observed patterns in the data. Finding the patterns is done via singular value decomposition iterations of the matrix while maintaining a low rank. The analysis revealed that while SoftImpute performed well in predicting ratings concerning MSE, its accuracy score was lower compared to emIRT.  Moreover, the emIRT algorithm's estimates exhibited strong relationships between user comments' positivity ratio and rating estimates, suggesting a more interpretable model.

The comparison between these methodologies revealed that each has its strengths and ideal applications. Ideal point estimation is particularly effective in contexts requiring a blend of content and collaborative filtering, offering a more personalized recommendation experience. On the other hand, SoftImpute shines in scenarios where computational efficiency and handling large, sparse datasets are crucial.

In conclusion, the exploration of these two methods underscores the importance of choosing the right algorithm based on the specific requirements and constraints of the application at hand. Using the ideal point estimations approach, normally a model for political science, in recommendation systems not only provided insights about the relationships between demographic data and movies but also improved the accuracy of the predictions. Future research could focus on integrating a more robust metric for individual fixed effects and offering a more nuanced model. Moreover, both of these models can be applied to other areas. For example, SoftImpute and other matrix completion algorithms can be applied to political science scenarios where they predict if a policy will be voted "Yes" by certain legislators. 

## 7. References

1. Barberá, Pablo. (2015). Birds of the Same Feather Tweet Together: Bayesian Ideal Point Estimation Using Twitter Data. *Political Analysis*, 23, 76–91.

2. Bafumi, Joseph, and Michael Herron. (2010). Leapfrog Representation and Extremism: A Study of American Voters and Their Members in Congress. *American Political Science Review*, 104, 519–42.

3. Bond, Robert, and Solomon Messing. (2015). Quantifying Social Media's Political Space: Estimating Ideology from Publicly Revealed Preferences on Facebook. *American Political Science Review*, 109, 62–78.

4. Harper, F. Maxwell, & Konstan, Joseph A. (2015). The MovieLens Datasets: History and Context. *ACM Transactions on Interactive Intelligent Systems (TiiS)*, 5(4), Article 19, 19 pages. [DOI:10.1145/2827872](http://dx.doi.org/10.1145/2827872)

5. Imai, Kosuke, Lo, James, & Olmsted, Jonathan. (2016). Fast Estimation of Ideal Points with Massive Data. *American Political Science Review*, 110(4), November, 2016.

6. Mazumder, Rahul, Hastie, Trevor, & Tibshirani, Robert. (2010). Spectral Regularization Algorithms for Learning Large Incomplete Matrices. *Journal of Machine Learning Research*, 11, 2287–2322.

7. Perry, Patrick. (2017). Fast moment-based estimation for hierarchical models. *Journal of the Royal Statistical Society: Series B*, 79(1), 267–291.

8. Wood, Simon N. (2006). *Generalized Additive Models*. Page 293.

